<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
	<meta name="generator" content="Hugo 0.92.2" /><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Lil&#39;Log</title>

<meta name="description" content="Document my learning notes.">
<meta name="author" content="Lilian Weng">
<link rel="canonical" href="https://lilianweng.github.io/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.949307ebc5cfbfc5e27c5ec3d332ce0be9137ec4137e02aefc52cf0267172e22.css" integrity="sha256-lJMH68XPv8XifF7D0zLOC&#43;kTfsQTfgKu/FLPAmcXLiI=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lilianweng.github.io/favicon_peach.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lilianweng.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lilianweng.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lilianweng.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lilianweng.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://lilianweng.github.io/index.xml">
<link rel="alternate" type="application/json" href="https://lilianweng.github.io/index.json">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-8161570-5', 'auto');
	
	ga('send', 'pageview');
}
</script><meta property="og:title" content="Lil&#39;Log" />
<meta property="og:description" content="Document my learning notes." />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://lilianweng.github.io/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Lil&#39;Log"/>
<meta name="twitter:description" content="Document my learning notes."/>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "Lil'Log",
  "url": "https://lilianweng.github.io/",
  "description": "Document my learning notes.",
  "thumbnailUrl": "https://lilianweng.github.io/favicon_peach.ico",
  "sameAs": [
      "index.xml", "https://scholar.google.com/citations?user=dCa-pW8AAAAJ\u0026hl=en\u0026oi=ao", "https://github.com/lilianweng", "https://www.instagram.com/lilianweng/", "https://twitter.com/lilianweng/", "https://paypal.me/LilianWeng", "https://venmo.com/lilianweng"
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lilianweng.github.io/" accesskey="h" title="Lil&#39;Log (Alt + H)">Lil&#39;Log</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lilianweng.github.io/" title="Posts">
                    <span class="active">Posts</span>
                </a>
            </li>
            <li>
                <a href="https://lilianweng.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://lilianweng.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://lilianweng.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://lilianweng.github.io/faq" title="FAQ">
                    <span>FAQ</span>
                </a>
            </li>
            <li>
                <a href="https://www.emojisearch.app/" title="emojisearch.app">
                    <span>emojisearch.app</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<article class="first-entry home-info">
    <header class="entry-header">
        <h1>üëã Welcome to Lil&rsquo;Log</h1>
    </header>
    <section class="entry-content">
        <p>Hi, this is Lilian. I&rsquo;m documenting my learning notes in this blog. Other than writing a ML blog, I&rsquo;m leading Applied Research at OpenAI on the side.</p>
    </section>
    <footer class="entry-footer">
        <div class="social-icons">
    <a href="index.xml" target="_blank" rel="noopener noreferrer me" title="Rss">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M4 11a9 9 0 0 1 9 9" />
    <path d="M4 4a16 16 0 0 1 16 16" />
    <circle cx="5" cy="19" r="1" />
</svg>
    </a>
    <a href="https://scholar.google.com/citations?user=dCa-pW8AAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer me" title="Other">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
    <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
</svg>
    </a>
    <a href="https://github.com/lilianweng" target="_blank" rel="noopener noreferrer me" title="Github">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
    </a>
    <a href="https://www.instagram.com/lilianweng/" target="_blank" rel="noopener noreferrer me" title="Instagram">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <rect x="2" y="2" width="20" height="20" rx="5" ry="5"></rect>
    <path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z"></path>
    <line x1="17.5" y1="6.5" x2="17.5" y2="6.5"></line>
</svg>
    </a>
    <a href="https://twitter.com/lilianweng/" target="_blank" rel="noopener noreferrer me" title="Twitter">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z">
    </path>
</svg>
    </a>
    <a href="https://paypal.me/LilianWeng" target="_blank" rel="noopener noreferrer me" title="Paypal">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M7.144 19.532l1.049-5.751c.11-.606.691-1.002 1.304-.948 2.155.192 6.877.1 8.818-4.002 2.554-5.397-.59-7.769-6.295-7.769H7.43a1.97 1.97 0 0 0-1.944 1.655L2.77 19.507a.857.857 0 0 0 .846.994h2.368a1.18 1.18 0 0 0 1.161-.969zM7.967 22.522a.74.74 0 0 0 .666.416h2.313c.492 0 .923-.351 1.003-.837l.759-4.601c.095-.523.597-.866 1.127-.819 1.86.166 5.567-.118 6.85-3.821.554-1.6.705-2.954.408-4.018"
        style="font-variation-settings:normal" stroke="currentColor" stroke-linejoin="miter" />
</svg>
    </a>
    <a href="https://venmo.com/lilianweng" target="_blank" rel="noopener noreferrer me" title="Kofi">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" preserveAspectRatio="xMidYMid meet"
    viewBox="0 -3 23 27" fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round"
    stroke-linejoin="round">
    <path
        d="M23.881 8.948c-.773-4.085-4.859-4.593-4.859-4.593H.723c-.604 0-.679.798-.679.798s-.082 7.324-.022 11.822c.164 2.424 2.586 2.672 2.586 2.672s8.267-.023 11.966-.049c2.438-.426 2.683-2.566 2.658-3.734c4.352.24 7.422-2.831 6.649-6.916zm-11.062 3.511c-1.246 1.453-4.011 3.976-4.011 3.976s-.121.119-.31.023c-.076-.057-.108-.09-.108-.09c-.443-.441-3.368-3.049-4.034-3.954c-.709-.965-1.041-2.7-.091-3.71c.951-1.01 3.005-1.086 4.363.407c0 0 1.565-1.782 3.468-.963c1.904.82 1.832 3.011.723 4.311zm6.173.478c-.928.116-1.682.028-1.682.028V7.284h1.77s1.971.551 1.971 2.638c0 1.913-.985 2.667-2.059 3.015z" />
</svg>
    </a>
</div>

    </footer>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Some Math behind Neural Tangent Kernel
    </h2>
  </header>
  <section class="entry-content">
    <p>Neural networks are well known to be over-parameterized and can often easily fit data with near-zero training loss with decent generalization performance on test dataset. Although all these parameters are initialized at random, the optimization process can consistently lead to similarly good outcomes. And this is true even when the number of model parameters exceeds the number of training data points.
Neural tangent kernel (NTK) (Jacot et al. 2018) is a kernel to explain the evolution of neural networks during training via gradient descent....</p>
  </section>
  <footer class="entry-footer"><span title='2022-09-08 10:00:00 -0700 PDT'>September 8, 2022</span>&nbsp;¬∑&nbsp;17 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Some Math behind Neural Tangent Kernel" href="https://lilianweng.github.io/posts/2022-09-08-ntk/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Generalized Visual Language Models
    </h2>
  </header>
  <section class="entry-content">
    <p>Processing images to generate text, such as image captioning and visual question-answering, has been studied for years. Traditionally such systems rely on an object detection network as a vision encoder to capture visual features and then produce text via a text decoder. Given a large amount of existing literature, in this post, I would like to only focus on one approach for solving vision language tasks, which is to extend pre-trained generalized language models to be capable of consuming visual signals....</p>
  </section>
  <footer class="entry-footer"><span title='2022-06-09 15:10:30 -0700 PDT'>June 9, 2022</span>&nbsp;¬∑&nbsp;25 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Generalized Visual Language Models" href="https://lilianweng.github.io/posts/2022-06-09-vlm/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Learning with not Enough Data Part 3: Data Generation
    </h2>
  </header>
  <section class="entry-content">
    <p>Here comes the Part 3 on learning with not enough data (Previous: Part 1 and Part 2). Let‚Äôs consider two approaches for generating synthetic data for training.
 Augmented data. Given a set of existing training samples, we can apply a variety of augmentation, distortion and transformation to derive new data points without losing the key attributes. We have covered a bunch of augmentation methods on text and images in a previous post on contrastive learning....</p>
  </section>
  <footer class="entry-footer"><span title='2022-04-15 15:10:30 -0700 PDT'>April 15, 2022</span>&nbsp;¬∑&nbsp;28 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Learning with not Enough Data Part 3: Data Generation" href="https://lilianweng.github.io/posts/2022-04-15-data-gen/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Learning with not Enough Data Part 2: Active Learning
    </h2>
  </header>
  <section class="entry-content">
    <p>This is part 2 of what to do when facing a limited amount of labeled data for supervised learning tasks. This time we will get some amount of human labeling work involved, but within a budget limit, and therefore we need to be smart when selecting which samples to label.
Notations    Symbol Meaning     $K$ Number of unique class labels.   $(\mathbf{x}^l, y) \sim \mathcal{X}, y \in \{0, 1\}^K$ Labeled dataset....</p>
  </section>
  <footer class="entry-footer"><span title='2022-02-20 00:00:00 +0000 UTC'>February 20, 2022</span>&nbsp;¬∑&nbsp;22 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Learning with not Enough Data Part 2: Active Learning" href="https://lilianweng.github.io/posts/2022-02-20-active-learning/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Learning with not Enough Data Part 1: Semi-Supervised Learning
    </h2>
  </header>
  <section class="entry-content">
    <p>When facing a limited amount of labeled data for supervised learning tasks, four approaches are commonly discussed.
 Pre-training &#43; fine-tuning: Pre-train a powerful task-agnostic model on a large unsupervised data corpus, e.g. pre-training LMs on free text, or pre-training vision models on unlabelled images via self-supervised learning, and then fine-tune it on the downstream task with a small set of labeled samples. Semi-supervised learning: Learn from the labelled and unlabeled samples together....</p>
  </section>
  <footer class="entry-footer"><span title='2021-12-05 00:00:00 +0000 UTC'>December 5, 2021</span>&nbsp;¬∑&nbsp;26 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Learning with not Enough Data Part 1: Semi-Supervised Learning" href="https://lilianweng.github.io/posts/2021-12-05-semi-supervised/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>How to Train Really Large Models on Many GPUs?
    </h2>
  </header>
  <section class="entry-content">
    <p>[Updated on 2022-03-13: add expert choice routing.] [Updated on 2022-06-10]: Greg and I wrote a shorted and upgraded version of this post, published on OpenAI Blog: ‚ÄúTechniques for Training Large Neural Networks‚Äù
In recent years, we are seeing better results on many NLP benchmark tasks with larger pre-trained language models. How to train large and deep neural networks is challenging, as it demands a large amount of GPU memory and a long horizon of training time....</p>
  </section>
  <footer class="entry-footer"><span title='2021-09-24 00:00:00 +0000 UTC'>September 24, 2021</span>&nbsp;¬∑&nbsp;21 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to How to Train Really Large Models on Many GPUs?" href="https://lilianweng.github.io/posts/2021-09-25-train-large/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>What are Diffusion Models?
    </h2>
  </header>
  <section class="entry-content">
    <p>[Updated on 2021-09-19: Highly recommend this blog post on score-based generative modeling by Yang Song (author of several key papers in the references)]. [Updated on 2022-08-27: Added classifier-free guidance, GLIDE, unCLIP and Imagen. [Updated on 2022-08-31: Added latent diffusion model.
So far, I‚Äôve written about three types of generative models, GAN, VAE, and Flow-based models. They have shown great success in generating high-quality samples, but each has some limitations of its own....</p>
  </section>
  <footer class="entry-footer"><span title='2021-07-11 00:00:00 +0000 UTC'>July 11, 2021</span>&nbsp;¬∑&nbsp;26 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to What are Diffusion Models?" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Contrastive Representation Learning
    </h2>
  </header>
  <section class="entry-content">
    <p>The goal of contrastive representation learning is to learn such an embedding space in which similar sample pairs stay close to each other while dissimilar ones are far apart. Contrastive learning can be applied to both supervised and unsupervised settings. When working with unsupervised data, contrastive learning is one of the most powerful approaches in self-supervised learning.
Contrastive Training Objectives In early versions of loss functions for contrastive learning, only one positive and one negative sample are involved....</p>
  </section>
  <footer class="entry-footer"><span title='2021-05-31 00:00:00 +0000 UTC'>May 31, 2021</span>&nbsp;¬∑&nbsp;39 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Contrastive Representation Learning" href="https://lilianweng.github.io/posts/2021-05-31-contrastive/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Reducing Toxicity in Language Models
    </h2>
  </header>
  <section class="entry-content">
    <p>Large pretrained language models are trained over a sizable collection of online data. They unavoidably acquire certain toxic behavior and biases from the Internet. Pretrained language models are very powerful and have shown great success in many NLP tasks. However, to safely deploy them for practical real-world applications demands a strong safety control over the model generation process.
Many challenges are associated with the effort to diminish various types of unsafe content:...</p>
  </section>
  <footer class="entry-footer"><span title='2021-03-21 00:00:00 +0000 UTC'>March 21, 2021</span>&nbsp;¬∑&nbsp;23 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Reducing Toxicity in Language Models" href="https://lilianweng.github.io/posts/2021-03-21-lm-toxicity/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Controllable Neural Text Generation
    </h2>
  </header>
  <section class="entry-content">
    <p>[Updated on 2021-02-01: Updated to version 2.0 with several work added and many typos fixed.] [Updated on 2021-05-26: Add P-tuning and Prompt Tuning in the ‚Äúprompt design‚Äù section.] [Updated on 2021-09-19: Add ‚Äúunlikelihood training‚Äù.]
There is a gigantic amount of free text on the Web, several magnitude more than labelled benchmark datasets. The state-of-the-art language models (LM) are trained with unsupervised Web data in large scale. When generating samples from LM by iteratively sampling the next token, we do not have much control over attributes of the output text, such as the topic, the style, the sentiment, etc....</p>
  </section>
  <footer class="entry-footer"><span title='2021-01-02 00:00:00 +0000 UTC'>January 2, 2021</span>&nbsp;¬∑&nbsp;42 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Controllable Neural Text Generation" href="https://lilianweng.github.io/posts/2021-01-02-controllable-text-generation/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>How to Build an Open-Domain Question Answering System?
    </h2>
  </header>
  <section class="entry-content">
    <p>[Updated on 2020-11-12: add an example on closed-book factual QA using OpenAI API (beta).
A model that can answer any question with regard to factual knowledge can lead to many useful and practical applications, such as working as a chatbot or an AI assistantü§ñ. In this post, we will review several common approaches for building such an open-domain question answering system.
Disclaimers given so many papers in the wild:
 Assume we have access to a powerful pretrained language model....</p>
  </section>
  <footer class="entry-footer"><span title='2020-10-29 00:00:00 +0000 UTC'>October 29, 2020</span>&nbsp;¬∑&nbsp;33 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to How to Build an Open-Domain Question Answering System?" href="https://lilianweng.github.io/posts/2020-10-29-odqa/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Neural Architecture Search
    </h2>
  </header>
  <section class="entry-content">
    <p>Although most popular and successful model architectures are designed by human experts, it doesn‚Äôt mean we have explored the entire network architecture space and settled down with the best option. We would have a better chance to find the optimal solution if we adopt a systematic and automatic way of learning high-performance model architectures.
Automatically learning and evolving network topologies is not a new idea (Stanley &amp; Miikkulainen, 2002). In recent years, the pioneering work by Zoph &amp; Le 2017 and Baker et al....</p>
  </section>
  <footer class="entry-footer"><span title='2020-08-06 00:00:00 +0000 UTC'>August 6, 2020</span>&nbsp;¬∑&nbsp;32 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Neural Architecture Search" href="https://lilianweng.github.io/posts/2020-08-06-nas/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Exploration Strategies in Deep Reinforcement Learning
    </h2>
  </header>
  <section class="entry-content">
    <p>[Updated on 2020-06-17: Add ‚Äúexploration via disagreement‚Äù in the ‚ÄúForward Dynamics‚Äù section.
Exploitation versus exploration is a critical topic in Reinforcement Learning. We‚Äôd like the RL agent to find the best solution as fast as possible. However, in the meantime, committing to solutions too quickly without enough exploration sounds pretty bad, as it could lead to local minima or total failure. Modern RL algorithms that optimize for the best returns can achieve good exploitation quite efficiently, while exploration remains more like an open topic....</p>
  </section>
  <footer class="entry-footer"><span title='2020-06-07 00:00:00 +0000 UTC'>June 7, 2020</span>&nbsp;¬∑&nbsp;36 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Exploration Strategies in Deep Reinforcement Learning" href="https://lilianweng.github.io/posts/2020-06-07-exploration-drl/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>The Transformer Family
    </h2>
  </header>
  <section class="entry-content">
    <p>It has been almost two years since my last post on attention. Recent progress on new and enhanced versions of Transformer motivates me to write another post on this specific topic, focusing on how the vanilla Transformer can be improved for longer-term attention span, less memory and computation consumption, RL task solving and more.
Notations    Symbol Meaning     $d$ The model size / hidden state dimension / positional encoding size....</p>
  </section>
  <footer class="entry-footer"><span title='2020-04-07 00:00:00 +0000 UTC'>April 7, 2020</span>&nbsp;¬∑&nbsp;25 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to The Transformer Family" href="https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Curriculum for Reinforcement Learning
    </h2>
  </header>
  <section class="entry-content">
    <p>[Updated on 2020-02-03: mentioning PCG in the ‚ÄúTask-Specific Curriculum‚Äù section. [Updated on 2020-02-04: Add a new ‚Äúcurriculum through distillation‚Äù section.
It sounds like an impossible task if we want to teach integral or derivative to a 3-year-old who does not even know basic arithmetics. That‚Äôs why education is important, as it provides a systematic way to break down complex knowledge and a nice curriculum for teaching concepts from simple to hard....</p>
  </section>
  <footer class="entry-footer"><span title='2020-01-29 00:00:00 +0000 UTC'>January 29, 2020</span>&nbsp;¬∑&nbsp;24 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Curriculum for Reinforcement Learning" href="https://lilianweng.github.io/posts/2020-01-29-curriculum-rl/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Self-Supervised Representation Learning
    </h2>
  </header>
  <section class="entry-content">
    <p>[Updated on 2020-01-09: add a new section on Contrastive Predictive Coding].  [Updated on 2020-04-13: add a ‚ÄúMomentum Contrast‚Äù section on MoCo, SimCLR and CURL.]  [Updated on 2020-07-08: add a ‚ÄúBisimulation‚Äù section on DeepMDP and DBC.]  [Updated on 2020-09-12: add MoCo V2 and BYOL in the ‚ÄúMomentum Contrast‚Äù section.]  [Updated on 2021-05-31: remove section on ‚ÄúMomentum Contrast‚Äù and add a pointer to a full post on ‚ÄúContrastive Representation Learning‚Äù]...</p>
  </section>
  <footer class="entry-footer"><span title='2019-11-10 00:00:00 +0000 UTC'>November 10, 2019</span>&nbsp;¬∑&nbsp;38 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Self-Supervised Representation Learning" href="https://lilianweng.github.io/posts/2019-11-10-self-supervised/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Evolution Strategies
    </h2>
  </header>
  <section class="entry-content">
    <p>Stochastic gradient descent is a universal choice for optimizing deep learning models. However, it is not the only option. With black-box optimization algorithms, you can evaluate a target function $f(x): \mathbb{R}^n \to \mathbb{R}$, even when you don‚Äôt know the precise analytic form of $f(x)$ and thus cannot compute gradients or the Hessian matrix. Examples of black-box optimization methods include Simulated Annealing, Hill Climbing and Nelder-Mead method.
Evolution Strategies (ES) is one type of black-box optimization algorithms, born in the family of Evolutionary Algorithms (EA)....</p>
  </section>
  <footer class="entry-footer"><span title='2019-09-05 00:00:00 +0000 UTC'>September 5, 2019</span>&nbsp;¬∑&nbsp;22 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Evolution Strategies" href="https://lilianweng.github.io/posts/2019-09-05-evolution-strategies/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Meta Reinforcement Learning
    </h2>
  </header>
  <section class="entry-content">
    <p>In my earlier post on meta-learning, the problem is mainly defined in the context of few-shot classification. Here I would like to explore more into cases when we try to ‚Äúmeta-learn‚Äù Reinforcement Learning (RL) tasks by developing an agent that can solve unseen tasks fast and efficiently.
To recap, a good meta-learning model is expected to generalize to new tasks or new environments that have never been encountered during training. The adaptation process, essentially a mini learning session, happens at test with limited exposure to the new configurations....</p>
  </section>
  <footer class="entry-footer"><span title='2019-06-23 00:00:00 +0000 UTC'>June 23, 2019</span>&nbsp;¬∑&nbsp;22 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Meta Reinforcement Learning" href="https://lilianweng.github.io/posts/2019-06-23-meta-rl/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Domain Randomization for Sim2Real Transfer
    </h2>
  </header>
  <section class="entry-content">
    <p>In Robotics, one of the hardest problems is how to make your model transfer to the real world. Due to the sample inefficiency of deep RL algorithms and the cost of data collection on real robots, we often need to train models in a simulator which theoretically provides an infinite amount of data. However, the reality gap between the simulator and the physical world often leads to failure when working with physical robots....</p>
  </section>
  <footer class="entry-footer"><span title='2019-05-05 00:00:00 +0000 UTC'>May 5, 2019</span>&nbsp;¬∑&nbsp;15 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Domain Randomization for Sim2Real Transfer" href="https://lilianweng.github.io/posts/2019-05-05-domain-randomization/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Are Deep Neural Networks Dramatically Overfitted?
    </h2>
  </header>
  <section class="entry-content">
    <p>[Updated on 2019-05-27: add the section on Lottery Ticket Hypothesis.]
If you are like me, entering into the field of deep learning with experience in traditional machine learning, you may often ponder over this question: Since a typical deep neural network has so many parameters and training error can easily be perfect, it should surely suffer from substantial overfitting. How could it be ever generalized to out-of-sample data points?
The effort in understanding why deep neural networks can generalize somehow reminds me of this interesting paper on System Biology ‚Äî ‚ÄúCan a biologist fix a radio?...</p>
  </section>
  <footer class="entry-footer"><span title='2019-03-14 00:00:00 +0000 UTC'>March 14, 2019</span>&nbsp;¬∑&nbsp;22 min&nbsp;¬∑&nbsp;Lilian Weng</footer>
  <a class="entry-link" aria-label="post link to Are Deep Neural Networks Dramatically Overfitted?" href="https://lilianweng.github.io/posts/2019-03-14-overfit/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="https://lilianweng.github.io/page/2/"> ¬ª</a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://lilianweng.github.io/">Lil&#39;Log</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
